{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f0407ac",
   "metadata": {},
   "source": [
    "# 02_Environment_Development\n",
    "\n",
    "Construct and test the custom multi-asset RL environment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504b8656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Install & Imports\n",
    "%pip install -e ..\n",
    "%pip install gymnasium stable-baselines3\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from src.environment.Multi_asset_env import MultiAsset21DeepHedgingEnv\n",
    "from src.environment.option_pricing import create_synthetic_option_chain\n",
    "from src.utils.data_utils import download_market_data\n",
    "from src.config.settings import get_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffce465",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Prepare Data & Option Chain\n",
    "cfg = get_config('data')\n",
    "df = download_market_data(\n",
    "    symbol=cfg['symbol'],\n",
    "    start_date=cfg['start_date'],\n",
    "    end_date=cfg['end_date'],\n",
    "    interval=cfg['interval']\n",
    ")\n",
    "\n",
    "opt_chain = create_synthetic_option_chain(\n",
    "    spot_data=df,\n",
    "    config=get_config('option')\n",
    ")\n",
    "\n",
    "# Define asset universe (same as in README)\n",
    "strikes = get_config('option')['strike_offsets']\n",
    "expiries = get_config('option')['expiry_days']\n",
    "types_ = get_config('option')['option_types']\n",
    "asset_universe = [\n",
    "    {'strike_offset': s, 'expiry_days': e, 'type': t}\n",
    "    for e in expiries for s in strikes for t in types_\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f934a949",
   "metadata": {},
   "source": [
    "## 2.3 Initialize Environment and Test State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011adda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = MultiAsset21DeepHedgingEnv(df, opt_chain, asset_universe)\n",
    "state, _ = env.reset()\n",
    "print(\"Observation shape:\", state.shape)\n",
    "print(\"Action space:\", env.action_space)\n",
    "print(\"Observation sample:\", state[:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffb0dc",
   "metadata": {},
   "source": [
    "## 2.4 Step Through Environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c10d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = env.action_space.sample()\n",
    "next_state, reward, done, trunc, info = env.step(action)\n",
    "print(\"Next state shape:\", next_state.shape)\n",
    "print(\"Reward:\", reward)\n",
    "print(\"Done:\", done)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4aa8e5",
   "metadata": {},
   "source": [
    "## 2.5 Visualize a Random Episode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf3dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, _ = env.reset()\n",
    "rewards = []\n",
    "for _ in range(50):\n",
    "    act = env.action_space.sample()\n",
    "    obs, r, done, trunc, _ = env.step(act)\n",
    "    rewards.append(r)\n",
    "    if done: break\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(rewards)\n",
    "plt.title(\"Random Episode Rewards (50 steps)\")\n",
    "plt.xlabel(\"Step\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
